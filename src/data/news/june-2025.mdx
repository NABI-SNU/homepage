---
title: June 2025
description: 'How Tiny RNNs, Inter-Brain Synchrony, and a Foundation Model Are Transforming Our Understanding of Cognition'
href: '/news/june-2025'
date: '2025-07-06'
references:
  - title: Discovering cognitive strategies with tiny recurrent neural networks
    authors:
      - Ji-An, L.
      - Benna, M. K.
      - Matter M. G.
    year: 2025
    journal: Nature
    doi: 10.1038/s41586-025-09142-4
    url: https://doi.org/10.1038/s41586-025-09142-4
  - title: Inter-brain neural dynamics in biological and artificial intelligence systems
    authors:
      - Zhang, X.
      - Phi, N.
      - Li, Q.
      - et al.
    year: 2025
    journal: Nature
    doi: 10.1038/s41586-025-09196-4
    url: https://doi.org/10.1038/s41586-025-09196-4
  - title: A foundation model to predict and capture human cognition
    authors:
      - Binz, M.
      - Elif, A.
      - Bethge, M.
      - et al.
    year: 2025
    journal: Nature
    doi: 10.1038/s41586-025-09215-4
    url: https://doi.org/10.1038/s41586-025-09215-4
---

## Discovering cognitive strategies with tiny recurrent neural networks

<img
  src="https://img-svr.nabiresearch.workers.dev/img/webp/MImlV1B.webp"
  alt="Tiny RNNs"
  style="width: 90%;"
  width="800"
  height="400"
/>

- Introduces a modeling approach using very small (1-4 units) recurrent neural
  networks (RNNs) to discover interpretable cognitive strategies in animal and
  human reward-learning tasks.
- Tiny RNNs outperform classical cognitive models in predicting choices,
  revealing novel behavioral patterns (e.g., variable learning rates,
  state-dependent perseveration) that are missed by standard models.
- The trained RNNs are interpretable through dynamical systems analysis,
  enabling visualization and comparison with classic cognitive theories.
- The framework allows dimensionality estimation of behavior and provides
  insights into both biological cognition and AI meta-reinforcement learning.

## Inter-brain neural dynamics in biological and artificial intelligence systems

<img
  src="https://img-svr.nabiresearch.workers.dev/img/webp/5YeJ3TX.webp"
  alt="Inter-brain neural dynamics"
  style="width: 90%;"
  width="800"
  height="400"
/>

- Examines how neural dynamics during social interaction can be partitioned
  into "shared" and "unique" subspaces in both mice and artificial agents.
- Finds GABAergic neurons in the dorsomedial prefrontal cortex (dmPFC)
  display significantly greater shared neural dynamics across brains than
  glutamatergic neurons, especially during social behavior.
- Disruption of shared neural subspace components impairs social interactions
  in both biological and artificial systems.
- Reveals that shared neural dynamics are a generalizable feature driving
  social behavior in interacting agents (biological or AI).

## A foundation model to predict and capture human cognition

<img
  src="https://img-svr.nabiresearch.workers.dev/img/webp/4CulrcI.webp"
  alt="Centaur"
  style="width: 90%;"
  width="800"
  height="400"
/>

- Introduces "Centaur," a large foundation model (fine-tuned Llama 3) trained
  on Psych-101, a massive dataset of trial-level human cognitive/behavioral
  data from 160 experiments.
- Centaur predicts human choices better than both base LLMs and domain-specific
  cognitive models, even in new tasks and domains, and its representations align
  more closely with human brain activity after tuning.
- Demonstrates strong generalization: can simulate human-like behavior with only
  natural language descriptions of tasks.
- Provides a platform for testing, falsifying, and refining cognitive theories
  at scale.
